import requests
from time import sleep
import pickle
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd

'''
三星终端列表网址：
https://www.phone888.cn/specs/?brand=5
https://www.phone888.cn/specs/?brand=5&z=2
https://www.phone888.cn/specs/?brand=5&z=3
……
https://www.phone888.cn/specs/?brand=5&z=68
'''


page = 68  #一共有68页


#获取所有手机的网址

list_allphone=[]  #爬取的目标手机列表页面共68页，将终端网址存放倒列表中

for i in range(page):
    list_allphone.append('https://www.phone888.cn/specs/?brand=5&z='+str(i+1))
#print(list_allphone)
list_allphone[0]='https://www.phone888.cn/specs/?brand=5'
print(list_allphone)

all_before=[] #将获取到的列表网页源码，存放到此列表中
for i in range(len(list_allphone)): #获取每一页手机列表页面的源码，后续从中提取各型号手机参数网址
    all_before.append(i)
    print(i)
    strhtml = requests.get(list_allphone[i])
    sleep(20)
    strhtml.encoding = 'utf-8'
    #print(strhtml.text)
    all_before.append(strhtml.text)

file_road = r'D:\pycharm\samsung\phone888_samsung_list'
pickle.dump(all_before,open(file_road,'wb')) #将列表打包保存到本地


#获取每一款终端的网页源码
file_road = r'D:\pycharm\samsung\phone888_samsung_list'
all_before=pickle.load(open(file_road,'rb'))
for j in range(5): #len(all_before)/2  #设置一次爬取的页面数
    num=47*2 #42、46页有问题  #由于在爬取过程中会因为各种原因中断，num设置重新开始爬取的页数
    i=num+j*2+1
    print(i)
    soup = BeautifulSoup(all_before[i], 'lxml')
    list_sony_all_source = []
    for link in soup.find_all('div', 'bl1'):
        phone_name = link.find('strong').get_text()
        list_sony_all_source.append(phone_name)
        print(phone_name)
        phone_href = 'https://www.phone888.cn' + link.find('a').get('href')
        list_sony_all_source.append(phone_href)
        print(phone_href)
        strhtml = requests.get(phone_href)
        sleep(15)
        strhtml.encoding = 'utf-8'
        list_sony_all_source.append(strhtml.text)
    file_road ='D:\pycharm\samsung\html\phone888_samsung_all_source_' + str(i)
    pickle.dump(list_sony_all_source, open(file_road, 'wb')) #每爬取一页保存一次列表
    print(file_road)



========================================================================================================================
#直接设置到底要爬取哪一页，比之前的方法要更好
import pickle
import requests
from time import sleep
from bs4 import BeautifulSoup

page=68
list_allphone=[]  #爬取的目标手机列表页面共7页，将网址存放倒列表中
for i in range(page):
    list_allphone.append('https://www.phone888.cn/specs/?brand=5&z='+str(i+1))
print(list_allphone)
list_allphone[0]='https://www.phone888.cn/specs/?brand=5'
print(list_allphone)

for j in range(3): #len(all_before)/2
    num=43
    i=num+j
    print(i)
    strhtml = requests.get(list_allphone[i])
    sleep(15)
    strhtml.encoding = 'utf-8'
    soup = BeautifulSoup(strhtml.text, 'lxml')
    list_sony_all_source = []
    for link in soup.find_all('div', 'bl1'):
        phone_name = link.find('strong').get_text()
        list_sony_all_source.append(phone_name)
        print(phone_name)
        phone_href = 'https://www.phone888.cn' + link.find('a').get('href')
        list_sony_all_source.append(phone_href)
        print(phone_href)
        strhtml = requests.get(phone_href)
        sleep(15)
        strhtml.encoding = 'utf-8'
        list_sony_all_source.append(strhtml.text)
    file_road ='E:\pycharm\phone\phone888_samsung\phone888_samsung_all_source_' + str(i)
    pickle.dump(list_sony_all_source, open(file_road, 'wb'))
    print(file_road)
========================================================================================================================

#提取终端属性

import pickle
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd

'''
file_road=r'E:\pycharm\phone\phone888_samsung\html\phone888_samsung_all_source_0'
a1 = pickle.load(open(file_road, 'rb'))
a2 = np.array(a1)
all_source = a2.reshape((int(len(a2) / 3), 3))
soup = BeautifulSoup(all_source[0][2], 'html.parser')
list_param = []
list_title=[]
ph_title=soup.find('strong').get_text()
list_title.append(ph_title)
list_title.append(ph_title)
list_param.append(list_title)
for link in soup.find_all('tr'):
    list_md = []
    for link1 in link.find_all('td'):
        list_md.append(link1.get_text())
        # print(link1.get_text())
    list_param.append(list_md)
print(list_param)


'''
page=68
result = pd.DataFrame([['title', 'param', 'brand', 'model']], columns=['title', 'param', 'brand', 'model'])
for j in range(page):
    # file_road=r'E:\pycharm\phone\phone888_samsung\html\phone888_samsung_all_source_0'
    file_road = 'E:\pycharm\phone\phone888_samsung\html\phone888_samsung_all_source_' + str(j)
    a1 = pickle.load(open(file_road, 'rb'))
    a2 = np.array(a1)
    all_source = a2.reshape((int(len(a2) / 3), 3))
    for i in range(len(all_source)):
        soup = BeautifulSoup(all_source[i][2], 'html.parser')
        # print(soup.prettify())  #按照标准的缩进格式的结构输出
        list_param = []
        list_title = []
        ph_title = soup.find('strong').get_text()
        list_title.append('ph_title')
        list_title.append(ph_title)
        list_param.append(list_title)
        for link in soup.find_all('tr'):
            list_md = []
            for link1 in link.find_all('td'):
                list_md.append(link1.get_text())
                # print(link1.get_text())
            list_param.append(list_md)
        # print(list_param)
        test = pd.DataFrame(list_param, columns=['title', 'param'])
        test['brand'] = 'samsung'
        test['model'] = all_source[i][0]
        # print(test)
        result = result.append(test)
result.to_csv(r"E:\pycharm\phone\phone888_samsung\phone888_samsung_20201127.csv",index=False,encoding='utf_8_sig')

--------------------------------------------------
#整理，规格化终端属性
import pandas as pd
import numpy as np
input_path=r"E:\pycharm\phone\phone888_samsung\phone888_samsung_20201127.csv"
name_phone=['参数名','参数','品牌','型号']
phone_all=pd.read_csv(open(input_path, 'rb'), names=name_phone,encoding = 'utf-8')

phone_xh=phone_all[['型号']]
phone_xh.drop_duplicates(inplace=True) #去重
col_xh = np.array(phone_xh).tolist()
col_xh.remove(['model']) #表中原有的字段名，删除
#print(col_xh)
col=phone_all[['参数名']]
col.drop_duplicates(inplace=True) #去重
list_col = np.array(col).tolist()
list_col.remove(['title'])  #表中原有的字段名，删除
#print(list_col)
col_re=[]
for i in range(len(list_col)):
	col_re.append(list_col[i][0])
#print(col_re)
template=pd.DataFrame(list_col,columns=['参数名'])
result = pd.DataFrame(np.arange(len(col_re)).reshape(1,len(col_re)), columns=col_re)
#print(template)

for i in range(len(col_xh)):
    print(col_xh[i][0])
    phone_3 = phone_all[phone_all['型号'] == col_xh[i][0]]
    phone_4 = pd.merge(template, phone_3, on='参数名', how='left')  # 连接
    phone_5 = phone_4[['参数名', '参数']]
    phone_6 = phone_5[['参数名', '参数']].groupby(by=['参数名']).max()
    phone_6.reset_index(inplace=True)
    phone_7 = pd.DataFrame(phone_6.values.T, index=phone_6.columns, columns=phone_6['参数名'])  # 转置
    phone_7.drop(index='参数名', inplace=True)  # 删除行'参数名'
    phone_7=phone_7[col_re]
    result = result.append(phone_7)
print(len(result))

result.to_csv(r"E:\pycharm\phone\phone888_samsung\phone888_samsung_20201127_done.csv",index=False,encoding='utf_8_sig')

